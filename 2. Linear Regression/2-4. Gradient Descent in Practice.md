# 2. Linear Regression- 4) Gradient Descent in Practice

## Feature Scaling
- 모든 feature가 비슷한 범위내에 있을경우 --> gradient descent가 더 빠르게 수렴

## Mean normalization
- xi를 xi−μi로 바꿔서 feature의 평균이 0이 되게 한다.
- x0=1에서는 적용하지 X

<img src ="https://user-images.githubusercontent.com/46768752/78246365-fbfa2000-7523-11ea-84c2-b51350da22ab.png"
width=600 height=250>

## Learning Rate
- J(θ): 매 iteration 마다 감소해야 함.
- Gradient descent 가 제대로 작동을 안할경우, α 값 ↓
but, α 값이 너무 작으면 gradient descent 가 수렴하는 데에 오래걸릴 수 있다는 문제 발생
(α 값을 3씩 곱하거나 나누며 조절하는 것을 추천)

<img src ="https://user-images.githubusercontent.com/46768752/78246374-00bed400-7524-11ea-9e8e-7fbef105f2da.png"
width=450 height=300>


## Debugging Gradient Descent


## Automatic Convergence Test

```
<영어단어>
- iteration: (계산, 컴퓨터 처리 절차의)반복
```